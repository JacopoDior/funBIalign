# fMSR funBIalign -----
# libraries employed by funBIalign
library(tidyverse)
library(dendextend)
library(data.table)
library(gridExtra)
library(Rcpp)
library(magic)

# functions -----
## 1. Portions creation -----
# create window_data dataset ccomprising all the portions embedded in the original data
# @my_data: the original data
# @portion_len: the length of the portion
create_lots <- function(my_data, portion_len) {
  # portion_len <- 50
  ints <- c()
  
  # is it a single observation (vector)?
  if (is.vector(my_data) == TRUE || dim(my_data)[1]==1) {
    totdim <- length(my_data)
    totobs <- 1
    
    # Create all intervals whose lenght is == portion_len
    start <- 1:(totdim - (portion_len)+ 1) # all possible starting points
    end <- portion_len:totdim # all possible ending points
    myint <- as.data.frame(rbind(ints, cbind(start, end, portion_len))) # all possible interval ranges
    curvelots <- dim(myint)[1] # lots covering a single curve
    
    # WINDOW DATA matrix creation
    window_data <- c()
    window_rownames <- c()
    for (i in 1:(curvelots)) {
      temp <- my_data[myint$start[i]:myint$end[i]] 
      window_rownames <- c(window_rownames, 
                           paste0(1:totobs, "_", myint[i, "start"], "_", myint[i, "end"]))
      window_data <- cbind(window_data, temp)
    }
    
    # setting to data.frame and changing adding rownames  
    window_data <- t(window_data) %>%
      as.data.frame()
    rownames(window_data) <- window_rownames
    
  } else { #data counts more than one observation
    totdim <- dim(my_data)[2]
    totobs <- dim(my_data)[1]
    
    # Create all intervals whose length is == portion_len
    start <- 1:(totdim - (portion_len) + 1) # all possible starting points
    end <- portion_len:totdim # all possible ending points
    myint <- as.data.frame(rbind(ints, cbind(start, end, portion_len))) # all possible interval ranges
    
    # WINDOW DATA matrix creation 
    window_data <- c()
    lots_list <- list()
    for(i in 1:dim(my_data)[1]){
      # get the curve
      curve <- my_data[i,]
      # get for the curve i all its lots
      curve_lots <-  lapply(1:(dim(myint)[1]),
                            function(x){
                              temp <- my_data[i, myint$start[x]:myint$end[x]]
                              temp
                            }
      )
      # create  the matrix with all the lots for the curve i 
      curve_lots <- do.call("rbind", curve_lots)
      # add rownames
      rownames(curve_lots) <- lapply(1:dim(curve_lots)[1],function(x){
        paste0(i, "_", myint[x, "start"], "_", myint[x, "end"])
      })
      window_data <- rbind(window_data, curve_lots)
    }
  }
  
  # set it as a matrix and omit rows with NAs
  window_data <- as.matrix(window_data)
  window_data <- na.omit(window_data)
  
  return(window_data)
}

## Step 2.  Hierarchical clustering based on the fMRS dissimilarity. -----

## HscoreC -----
# compute the fMRS-based dissimilarity dfMSR without considering the accolytes
# @mat: a window_data matrix
cppFunction('NumericMatrix HscoreC(NumericMatrix mat){
  unsigned int outrows = mat.nrow();
  double d;
  int p = mat.ncol();
  Rcpp::NumericVector x(p);
  double p_inv = 1/(double)p;
  Rcpp::NumericMatrix res(outrows,outrows);
  
  for (int i = 0; i < res.nrow(); i++) {
     x = mat.row(i);
    for (int j = 0; j < i; j++) {
      d = sum(pow(x - sum(x)*p_inv - (x + mat.row(j))*0.5 + sum(x + mat.row(j))*(0.5*p_inv), 2.0))*p_inv;
      res(j,i)=d;
      res(i,j)=d;
    }
  }
         
  return res;
}')

# fMSR ADJ ----
# compute the adjusted fMSR for a given window-data matrix
# @mat: a window_data matrix
fMSR_adj <- function(mat){
  if(is.null(nrow(mat))){
    score <- 0
  }else{
    score <- sum((mat - rowMeans(mat) - matrix(colMeans(mat),nrow=nrow(mat),ncol=ncol(mat),byrow=TRUE) + mean(mat)) ^2)/(nrow(mat)*ncol(mat))
    
    m <- dim(mat)[1]
    if(m>2){
      compare_value <- c()
      for( k in 2:(m-1)){
        compare_value <- c(compare_value,k^2/(k^2-1))
      }
      score <- score/prod(compare_value)
    }
  }
  score 
}


# compute the fMRS-based dissimilarity dfMSR with the accolytes corrections
# @my_data: the original data
# @window_data: the window-data matrix as generated by create_lots
# @portion_len:  the length of the portion
create_distance <- function(my_data, window_data, portion_len) {
  p_inv <- 1 / portion_len
  temp_D <- HscoreC(window_data)
  curvelots <- dim(window_data)[1]
  
  # dealing with accolites
  rownames(temp_D) <- colnames(temp_D) <- rownames(window_data)
  
  # Modify accolites - single line
  M <- max(temp_D) + 1000 # very large distance for accolites
  overlap <- floor(portion_len / 2) # number of right/left accolites
  
  # create Block matrix for accolites
  # single line
  if ((dim(my_data) %>% is.null() == T) | (dim(my_data)[1] == 1)) { 
    # block_m
    block_m <- matrix(0, curvelots, curvelots) # all zeros matrix
    for (i in 1:(dim(block_m)[1])) {
      r_accolites <- (i + 1):(i + overlap) # accolites to the right
      l_accolites <- (i - 1):(i - overlap) # accolites to the left
      block_m[i, r_accolites[which(r_accolites <= curvelots)]] <- M
      block_m[i, l_accolites[which(l_accolites >= 1)]] <- M
    }
    
    temp_D <- temp_D + block_m
    temp_D <- as.dist(temp_D)
  } else {
    # get number of pieces for each curve
    numerosity <- lapply(
      rownames(window_data) %>% str_split("_"),
      function(x) {
        x[1] %>% as.numeric()
      }
    ) %>% 
      unlist() %>%
      table()
    
    # get max numerosity - curves with most lots
    max_num <- max(numerosity)
    
    # general block matrix
    block_m <- matrix(0, max_num, max_num)
    for (i in 1:(dim(block_m)[1])) {
      r_accolites <- (i + 1):(i + overlap) # accolites to the right
      l_accolites <- (i - 1):(i - overlap) # accolites to the left
      block_m[i, r_accolites[which(r_accolites <= max_num)]] <- M
      block_m[i, l_accolites[which(l_accolites >= 1)]] <- M
    }
    
    temp_D[1:numerosity[1], 1:numerosity[1]] <- temp_D[1:numerosity[1], 1:numerosity[1]] + 
      block_m[1:numerosity[1], 1:numerosity[1]]
    until_here <- numerosity[1]
    for(i in 2:length(numerosity)){
      temp_index <- (until_here + 1) : (until_here + numerosity[i])
      temp_D[temp_index, temp_index] <- temp_D[temp_index, temp_index] + 
        block_m[1:numerosity[i], 1:numerosity[i]]
      until_here <- until_here + numerosity[i]
    }
    
    rm(block_m)
    temp_D <- as.dist(temp_D)
  }
  return(temp_D)
}


# performs agglomerative hierarchical clustering to get Tree and then cut it. In this way,
# it creates multiple minidend (tree_s)
# @ adj_fMSR: the adjusted fMSR created by create_distance
# @ window_data: a window_data matrix

get_minidend <- function(adj_fMSR, window_data){
  # generate dendrogram
  total_hc <- fastcluster::hclust(adj_fMSR, method = "complete")
  total_dend <- as.dendrogram(total_hc) # transform in dendrogram
  
  # Identify height_cut
  # It is made by ordering all the heights and identifying the largest gap.
  # The height cut corresponds to the mean between the elements generating the gap
  cut_position <- sort(total_hc$height) %>% diff() %>% which.max()
  height_cut <- sort(total_hc$height)[c(cut_position, cut_position + 1)] %>%
    mean()
  
  # Generating minidend
  minidend <- cut(total_dend, h = height_cut)$lower
  return(minidend)
}

## Step 3. ----

# get seeds and families
# @ minidend: one sub-tree (tree_s)
# @ window_data: a window_data matrix
# @ min_card: the minimum number of portions that a motif should have
get_path_complete <- function(minidend, window_data, min_card){
  all_paths <- lapply(minidend,
                      find_recommended_path,
                      window_data = window_data,
                      min_card = min_card)
  return(all_paths)
}

# given a tree_s it gives you details the families of the motifs and returns recommended nodes.
# It returns a list with
# @ minidend: one sub-tree (tree_s)
# @ window_data: a window_data matrix
# @ min_card: the minimum number of portions that a motif should have
find_recommended_path <- function(minidend, window_data, min_card){
  # get leaves for each node
  node_list <- minidend %>% partition_leaves()
  
  # get number of leaves in each node as a vector
  node_leaves  <- node_list %>%
    lapply(length) %>%
    unlist() %>%
    as.data.table() %>%
    setnames(,'node_leaves')
  
  # get branches heights
  node_heights <- minidend %>%
    get_nodes_xy() %>%
    as.data.table() %>%
    setnames(,c('x','y')) 
  
  node_heights <- node_heights[,'y']
  
  # bind together on a dataframe with deep-first search order
  temp <- cbind(node_leaves, node_heights) %>%
    mutate(depth_order = 1:length(node_leaves)) # deep-first search order
  
  # generate for each nodes (using function get_parents)
  node_parents <- lapply(node_list, get_parents, node_list = node_list )
  
  # minimum cardinality (minimum number of node leaves - selected by the user)
  min_card <- min_card
  # add column interesting according to the number of leaves and the min_card
  temp <- temp %>%
    filter(node_leaves >= min_card) %>%
    arrange(node_leaves, y)
  
  # no node with at least min_card branches -> EXIT (return list with NULL)
  if(dim(temp)[1] == 0){
    return(NULL)
  }
  
  # find the nodes that need to be deleted because parents of minimal ones
  delete_nodes <- c()
  for(i in 1:dim(temp)[1]){
    node_index   <- temp$depth_order[i] # focus node
    delete_now   <- node_parents[[node_index]] # all parents nodes of the focus
    delete_nodes <- c(delete_nodes,
                      delete_now[delete_now != node_index])
  }
  
  # seed nodes
  temp <- temp %>%
    filter(!(depth_order %in% unique(delete_nodes)))
  
  # crossing points between seed nodes
  seed_parents <- node_parents[temp$depth_order]
  all_parents  <- seed_parents %>% unlist() %>% unique()
  
  seed_path <- list()
  for(i in 1:length(seed_parents)){
    my_parent      <- seed_parents[[i]]
    the_rest       <- seed_parents[-i] %>% unlist() %>% unique() %>% sort()
    if(!(is.null(the_rest))){
      cross_point    <- intersect(my_parent, the_rest) %>% max()
      seed_path[[i]] <- my_parent[my_parent > cross_point]
    }else{
      seed_path[[i]] <- my_parent
    }
  }
  
  # add column with parents till the new crossing
  temp$parents <- lapply(seed_path, toString) %>% unlist()
  
  # get the list of elements for each node in the seed_path
  seed_path_list <- lapply(seed_path, function(x){node_list[x]}) # names of elements  
  
  # get the list of h-score adjusted for each node in the seed_path
  score_path_list <- lapply(seed_path, function(x){
    lapply(x, function(x){window_data[node_list[[x]],] %>% fMSR_adj()})}
  )
  
  recommendation <- lapply(score_path_list, recommend_node) %>% unlist()
  temp$recommended <- recommendation
  
  # get information about recommended nodes (labels and scores)
  recommended_node_labels <- list()
  recommended_node_scores  <- c()
  for(i in 1:length(seed_path_list)){
    recommended_index <- recommendation[i]
    recommended_node_labels[[i]] <- seed_path_list[[i]][[recommended_index]]
    recommended_node_scores[i]   <- score_path_list[[i]][[recommended_index]]
  }
  
  
  res <- list("seed_path_info"  = temp,
              "seed_path_list"  = seed_path_list,
              "score_path_list" = score_path_list,
              "recommended_node_labels" = recommended_node_labels,
              "recommended_node_scores" = recommended_node_scores
  )
  return(res)
}

# find all parents for a given node
# @node: a node you are interested in
# @node_list: the list of all nodes
get_parents <- function(node, node_list){
  which(lapply(node_list, function(x){all(node %in% x)}) %>% unlist())
}

# it returns a recommended node for every family
# @ node: a node
recommend_node <- function(node){
  xx <- unlist(node)
  
  if(length(xx) >= 2){
    diff_xx <- diff(xx)
    if(all(diff(xx)>0)){ # always increasing h-score: stop before maximum growth rate
      return((diff_xx/xx[1:length(xx)-1]) %>% which.max()) # or +1
    }else{ #also decreasing: stop minimum hscore
      return(which.min(xx))
    }
  }else{
    return(1)
  }
}

## 4. Post-processing ----
# get_accolites returns all the possible accolites for a given motif/node
# @leaf_label
# @window_data
# @portion_len
# @multiple: binary variable set it to TRUE if the data counts more than one observation
get_accolites <- function(leaf_label, window_data, portion_len, multiple){
  # number of overlapping elements that define accolites
  overlap <- floor(portion_len/2)
  leaf_label_curve <-  (strsplit(leaf_label, '_') %>% 
                          unlist() %>%
                          as.numeric())[1]
  
  leaf_index  <- which(rownames(window_data) == leaf_label) # index in window_data
  r_accolites <- (leaf_index+1):min(leaf_index+overlap, dim(window_data)[1])  # accolites to the right
  l_accolites <- (leaf_index-1):max(leaf_index-overlap,0)  # accolites to the left
  accolites   <- c(leaf_index, l_accolites, r_accolites) # overall accolites
  
  # get the accolites
  leaf_accolites <- rownames(window_data)[accolites]
  leaf_accolites <- leaf_accolites[!is.na(leaf_accolites)] #remove NAs
  # check if they come from the same curve (multiple curves cases)
  if(multiple == TRUE){
    leaf_accolites_curve <- strsplit(leaf_accolites, '_') %>% 
      unlist() %>%
      as.numeric() %>%
      matrix(ncol=3, byrow=T) %>%
      as.data.frame()
    to_delete <- which(leaf_accolites_curve$V1 != leaf_label_curve)
    if(length(to_delete) > 0){
      leaf_accolites <- leaf_accolites[-to_delete]
    }
  }
  return(leaf_accolites)
}

# compare node_1 to node_2 and returns TRUE if node_1 is embedded in node_2 and
# FALSE otherwise
compare_nodes <- function(node_1, node_2){
  accolites_1    <- lapply(node_1, get_accolites, window_data, 50) %>% unlist()
  common_elements <- (node_2 %in% accolites_1) %>% sum() 
  if(length(node_1) == common_elements){ 
    TRUE # if the number of common elements is equal to node_1 cardinality
  }else{
    FALSE 
  }
}


